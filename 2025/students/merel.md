---
student_name: "Merel"
project_title: "Cover Me"
context: Autonomous Context
year: 2024-2025
main_image: merel/1DN54cRRPlfMgVjIgGJ1puvwvmrplCoOW.jpg
images:
  - merel/1b_sxlQSnMia_rKtcKsNt554oY8uSXmfk.jpg
  - merel/126sCYXK-4HzyOnhRFeaW02kS_Rg_QVam.jpg
  - merel/1-5HfnB-04RYf42azVLSoPz6kAFviqAZY.jpg
  - merel/1Py7337upnwoJ-0MghPCFj_cUd6dU8fA2.jpg
social_links:
  - "https://merelouwerkerk.cargo.site"
  - "https://www.instagram.com/https://www.instagram.com/a.o.merel?igsh=MThsZzBveDRvc2Jzdg=="
---
A live webcam on Texel streams everything it captures — people, movement, everyday life. Cover Me reflects on surveillance technologies and their role in systems of control and exposure. Using an object-detection algorithm that visually obscures yet also protects humans, the work questions the ethics of observation and offers a subtle act of resistance.

This project researches the influence and (in)visibility of surveillance in our society, focusing on how observation technologies target the recognition of human bodies. The starting point is a publicly accessible webcam on Texel (NL), which records swimmers and passersby daily. It captures a calm environment that seems ordinary. Yet, these seemingly innocent images raise fundamental questions about privacy, consent, and power: who watches and who is watched?

Using a live object detection algorithm adapted and extended for this project, the installation reveals both the technological potential and the possibility for critical protest. The installation shows two video streams: the original livestream where an algorithm detects and simultaneously ‘protects’ people, and a translation of this output into ‘human language.’ This creates tension between observation and interpretation, technology and humanity.

The video installation invites the viewer to reflect on the feeling of being watched, as well as the voyeuristic experience of watching the livestream itself. Surveillance is not just shown but activated as a visual system that raises ethical concerns. As artist, I take a critical stance by questioning the normalization and easy access to such livestreams; I try to protect people using technology that also detects them.

By positioning the screens opposite each other, a dialogue forms between live footage and algorithm, as if they recognize and challenge each other’s presence.
